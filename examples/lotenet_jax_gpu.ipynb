{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not working fully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "import orbax.checkpoint\n",
    "import optax\n",
    "import jax\n",
    "from flax.training import train_state, orbax_utils\n",
    "import jax.numpy as jnp\n",
    "import jax.profiler\n",
    "from tn4ml.models.lotenet import loTeNet\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "- make sure you have JAX and CUDA versions set up correctly\n",
    "- refer to:\n",
    "    - [Jax for GPU](https://jax.readthedocs.io/en/latest/installation.html#nvidia-gpu)\n",
    "    - [Jax releases with CUDA](https://storage.googleapis.com/jax-releases/jax_cuda_releases.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus_to_use = jax.devices('gpu')\n",
    "gpus_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for saving checkpoints\n",
    "ckpt_dir = '/Users/emapuljak/WorkDirs/medical_study'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['batch_size'] = 4\n",
    "config['epochs'] = 5\n",
    "config['learning_rate'] = 1e-3\n",
    "config['seed'] = 42\n",
    "config['validation_split'] = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_model = {}\n",
    "config_model['kernel'] = 2\n",
    "config_model['output_dim'] = 10 # number of classes\n",
    "config_model['bond_dim'] = 5\n",
    "config_model['virtual_dim'] = config_model['bond_dim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 12\n",
    "test_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check on fashion_mnist\n",
    "\n",
    "train_ds, test_ds = tfds.load('fashion_mnist', split=['train','test'], as_supervised=True, data_dir='/eos/user/e/epuljak/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad_image(image, target_size):\n",
    "    if len(image.shape) not in [2,3]:\n",
    "        ValueError(\"Image must be 2D or 3D!\")\n",
    "\n",
    "    current_size = np.array(image.shape)\n",
    "    pad_width = target_size - current_size\n",
    "\n",
    "    # Calculate padding for each side\n",
    "    pad_before = pad_width // 2\n",
    "    pad_after = pad_width - pad_before\n",
    "\n",
    "    # Pad the image with zeros\n",
    "    if len(current_size) == 3:\n",
    "        padded_image = np.pad(image, ((pad_before[0], pad_after[0]),\n",
    "                                    (pad_before[1], pad_after[1]),\n",
    "                                    (pad_before[2], pad_after[2])),\n",
    "                            mode='constant', constant_values=0)\n",
    "    else:\n",
    "        padded_image = np.pad(image, ((pad_before[0], pad_after[0]),\n",
    "                                    (pad_before[1], pad_after[1])),\n",
    "                            mode='constant', constant_values=0)\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image_shape(image, k):\n",
    "    # check if image needs to be zero padded - each dimension to power of k\n",
    "    new_shape = [int(k ** np.ceil(np.log2(dim) / np.log2(k))) for dim in image.shape]\n",
    "    if new_shape != image.shape:\n",
    "        image = zero_pad_image(image, new_shape)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=[]; train_labels=[]\n",
    "for image, labels in train_ds:\n",
    "    # zero pad if needed\n",
    "    image = np.array(image)/255.0\n",
    "    image = check_image_shape(image, config_model['kernel'])\n",
    "\n",
    "    train_images.append(image)\n",
    "\n",
    "    train_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=[]; test_labels=[]\n",
    "for image, labels in test_ds:\n",
    "    # zero pad if needed\n",
    "    image = np.array(image)/255.0\n",
    "    image = check_image_shape(image, config_model['kernel'])\n",
    "\n",
    "    test_images.append(image)\n",
    "\n",
    "    test_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images[:train_size])\n",
    "train_labels = np.array(train_labels[:train_size])\n",
    "\n",
    "test_images = np.array(test_images[:test_size])\n",
    "test_labels = np.array(test_labels[:test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size=len(train_images), seed=1234).batch(config['batch_size'], drop_remainder=True)\n",
    "train_dataset_labels = tf.data.Dataset.from_tensor_slices(train_labels).shuffle(buffer_size=len(train_labels), seed=1234).batch(config['batch_size'], drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model loTeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loTeNet(input_dim=train_images[0].shape,\\\n",
    "                   output_dim=config_model['output_dim'],\\\n",
    "                    bond_dim=config_model['bond_dim'],\\\n",
    "                    kernel = config_model['kernel'],\\\n",
    "                    virtual_dim = config_model['virtual_dim'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(config['seed'])\n",
    "optimiser = optax.adam(learning_rate=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_step(key, model, optimiser, image_shape):\n",
    "  dummy_input = jnp.ones(shape=image_shape) # Dummy Input for initialization of MODEL\n",
    "  params = model.init(key, dummy_input)\n",
    "  state = train_state.TrainState.create(apply_fn=model.apply,\n",
    "                                        params=params['params'],\n",
    "                                        tx=optimiser)\n",
    "  #opt_state = optimiser.init(params)\n",
    "\n",
    "  @jax.jit\n",
    "  def parallelized_loss(loss, inputs, devices, in_axes=(None, 0)):\n",
    "    v_loss = jax.vmap(loss, in_axes=in_axes)\n",
    "    p_loss = jax.pmap(v_loss, axis_name='batch')\n",
    "\n",
    "    return p_loss(inputs)\n",
    "  \n",
    "  @jax.jit\n",
    "  def loss_fn(params, data, y_true):\n",
    "    # vmap for batching\n",
    "    #with jax.Device(gpus_to_use):\n",
    "    y_pred = parallelized_loss(state.apply_fn, ({'params': params}, data), gpus_to_use)\n",
    "    \n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(y_pred, y_true).mean()\n",
    "    return loss\n",
    "\n",
    "  @jax.jit\n",
    "  def train_step(state, data, y_true):\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(state.params, data, y_true)\n",
    "\n",
    "    #updates, opt_state = optimiser.update(grads, opt_state, params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "\n",
    "    return state, loss\n",
    "\n",
    "  return train_step, state\n",
    "\n",
    "def model_train(n_epochs, train_dataset, targets, state, train_step_func):\n",
    "    history={}\n",
    "    history['loss'] = []\n",
    "    for epoch in range(n_epochs):\n",
    "        loss_batch = 0\n",
    "        batch_num = 0\n",
    "        \n",
    "        for batch_x, batch_y in zip(list(train_dataset.as_numpy_iterator()), list(targets.as_numpy_iterator())):\n",
    "            state, loss_curr = train_step_func(state, jnp.asarray(batch_x), jnp.asarray(batch_y))\n",
    "            loss_batch += loss_curr\n",
    "            batch_num+=1\n",
    "        \n",
    "        print(f'Epoch: {epoch}, loss = {loss_batch/batch_num}')\n",
    "        history['loss'].append(loss_batch/batch_num)\n",
    "    return history, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step, state = create_train_step(key, model, optimiser, train_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, state = model_train(config['epochs'], train_dataset, train_dataset_labels, state, train_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss function\n",
    "plt.figure()\n",
    "plt.plot(range(len(history['loss'])), history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model checkpoints \n",
    "- **TODO**: check does it work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_data = jax.profiler.get_trace()\n",
    "print(trace_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = {}\n",
    "ckpt['model'] = state\n",
    "ckpt['history'] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(ckpt)\n",
    "orbax_checkpointer.save(f'{save_dir}/test_save', ckpt, save_args=save_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore checkpoints\n",
    "raw_restored = orbax_checkpointer.restore(f'{save_dir}/test_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_restored['model']['params'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(params, data, y_true):\n",
    "    # vmap for batching\n",
    "    y_pred = jax.vmap(state.apply_fn, in_axes=(None, 0))({'params': params}, data)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(y_pred, y_true).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(raw_restored['model']['params'], test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
